{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T05:46:18.207819Z",
     "start_time": "2017-06-21T05:46:18.184464Z"
    }
   },
   "source": [
    "#### Reference:\n",
    "- https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "-  https://github.com/wiseodd/generative-models/blob/master/VAE/vanilla_vae/vae_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T06:41:06.511818Z",
     "start_time": "2017-06-21T06:41:06.487497Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T06:53:38.938712Z",
     "start_time": "2017-06-21T06:53:38.904385Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseConfig():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 10\n",
    "        self.cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 100\n",
    "\n",
    "config = BaseConfig()\n",
    "\n",
    "# seed\n",
    "torch.manual_seed(args.seed)\n",
    "if config.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T06:53:39.111975Z",
     "start_time": "2017-06-21T06:53:38.940408Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../../datasets/', train=True, download=False, transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../../../datasets', train=False, download=False, transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T06:53:39.244046Z",
     "start_time": "2017-06-21T06:53:39.113730Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(VAE, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # P(Z|X)\n",
    "        self.fc_xh = nn.Linear(784, config.h_size)\n",
    "        self.fc_hz_mu = nn.Linear(config.h_size, config.z_size)\n",
    "        self.fc_hz_var = nn.Linear(config.h_size, config.z_size)\n",
    "\n",
    "        # P(X|Z)\n",
    "        self.fc_zh = nn.Linear(config.z_size, config.h_size)\n",
    "        self.fc_hx = nn.Linear(config.h_size, 784)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                torch.nn.init.xavier_normal(module.weight.data)\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x [batch_size, 28*28]\n",
    "        Return:\n",
    "            mu [batch_size, z_size]\n",
    "            log_variance [batch_size, z_size]\n",
    "        \"\"\"\n",
    "        h = self.relu(self.fc_xh(x))\n",
    "\n",
    "        mu = self.fc_hz_mu(h)\n",
    "        log_variance = self.fc_hz_var(h)\n",
    "\n",
    "        return mu, log_variance\n",
    "\n",
    "    def reparameterize(self, mu, log_variance):\n",
    "        \"\"\"Sample z via reparameterization\"\"\"\n",
    "        std = log_variance.mul(0.5).exp_()\n",
    "\n",
    "        # Sampling from gaussian distribution\n",
    "        if self.config.cuda:\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "\n",
    "        z = eps.mul(std).add_(mu)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"Reconstruct X with P(X|Z)\"\"\"\n",
    "        h = self.relu(self.fc_zh(z))\n",
    "        return self.sigmoid(self.fc_hx(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode X => Z\n",
    "        mu, log_variance = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, log_variance)\n",
    "\n",
    "        # Reconstruct Z => X\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, log_variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T06:53:39.320610Z",
     "start_time": "2017-06-21T06:53:39.245866Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "model.initialize()\n",
    "\n",
    "binary_xent = nn.BCELoss()\n",
    "binary_xent.size_average = False # losses are summed\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-21T07:03:17.839465Z",
     "start_time": "2017-06-21T07:03:17.727232Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch):\n",
    "    model.train() # set to training mode\n",
    "    train_loss = 0\n",
    "    for batch_idx, (images, _) in enumerate(train_loader):\n",
    "        images = Variable(images) # [batch_size, 1, 28, 28]\n",
    "        if args.cuda:\n",
    "            images = images.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_images, mu, log_variance = model(images)\n",
    "        loss = loss_function(recon_images, images, mu, log_variance)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx > 0 and batch_idx % args.log_interval == 0:\n",
    "            log_string = f'Epoch {epoch} | '\n",
    "            log_string += f'[{batch_idx*len(images)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\t'\n",
    "            log_string += f'Loss: {loss.data[0] / len(images):.4f}'\n",
    "            print(log_string)\n",
    "\n",
    "    print(f'Epoch {epoch} | Average Loss: {train_loss / len(train_loader.dataset):.4f}\\n')\n",
    "\n",
    "    # Save original images\n",
    "    if epoch == 1:\n",
    "        images = images.view(images.size(0), 1, 28, 28)\n",
    "        save_image(images.data, './data/real_images.png')\n",
    "\n",
    "\n",
    "    # Save reconstructed images\n",
    "    recon_images = recon_images.view(recon_images.size(0), 1, 28, 28)\n",
    "    save_image(recon_images.data, './data/recon_images-%d.png' % (epoch))\n",
    "\n",
    "for i in range(2):\n",
    "    train_one_epoch(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mldemo]",
   "language": "python",
   "name": "conda-env-mldemo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "65px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "927px",
    "left": "0px",
    "right": "1494.67px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
